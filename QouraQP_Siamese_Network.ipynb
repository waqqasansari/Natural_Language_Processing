{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QouraQP_Siamese_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBx/oXqhE4M1Mtqcqw911V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waqqasansari/Natural_Language_Processing/blob/master/QouraQP_Siamese_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vYQ80-DwZCI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "9a14b5fa-18dc-4b80-9718-80ddc1ea0308"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wcsmEC6wrtc",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "outputId": "39f0e067-5576-475b-a631-4095659f3956"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cede320d-bf53-493a-856e-69970d5f3ba1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cede320d-bf53-493a-856e-69970d5f3ba1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"waqqas\",\"key\":\"5985e115491a47485587329f9879e89c\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icd5UTPSX59V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVXdwvWMZRoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z42_qByeZlbv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "fe26130d-c33e-4bf5-ba26-00586774cc0b"
      },
      "source": [
        "!kaggle competitions download -c quora-question-pairs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            " 92% 105M/114M [00:01<00:00, 52.3MB/s] \n",
            "100% 114M/114M [00:01<00:00, 65.8MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 43% 9.00M/21.2M [00:00<00:00, 15.3MB/s]\n",
            "100% 21.2M/21.2M [00:00<00:00, 31.0MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "100% 4.95M/4.95M [00:00<00:00, 33.2MB/s]\n",
            "\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nZmjPg3ajBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q -U trax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSiPhs8DbKS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0c515ffe-07a8-4f4a-8971-fe8a74fb3e55"
      },
      "source": [
        "import os\n",
        "import nltk\n",
        "import trax\n",
        "from trax import layers as tl\n",
        "from trax.supervised import training\n",
        "from trax.fastmath import numpy as fastnp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rnd\n",
        "nltk.download('punkt')\n",
        "# set random seeds\n",
        "rnd.seed(34)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F7p2OTTbSaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3e2ee9a7-c6c4-4b9b-f5e0-6dbf9e50a981"
      },
      "source": [
        "!unzip /content/train.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/train.csv.zip\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrlqRNGTcKll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6899677d-ca91-4a7f-8176-e475ad50e317"
      },
      "source": [
        "!unzip /content/test.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/test.csv.zip\n",
            "  inflating: test.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5-wowpIcJss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "d65aa1e9-a928-46f9-ef26-588947f5a95b"
      },
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "N = len(data)\n",
        "print('Number of question pairs:', N)\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of question pairs: 404290\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>When do you use シ instead of し?</td>\n",
              "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "5   5    11  ...  I'm a triple Capricorn (Sun, Moon and ascendan...            1\n",
              "6   6    13  ...  What keeps childern active and far from phone ...            0\n",
              "7   7    15  ...          What should I do to be a great geologist?            1\n",
              "8   8    17  ...              When do you use \"&\" instead of \"and\"?            0\n",
              "9   9    19  ...  How do I hack Motorola DCX3400 for free internet?            0\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3I094iwceSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_train = 300000\n",
        "N_test = 10*1024\n",
        "data_train = data[:N_train]\n",
        "data_test = data[N_train : N_train+N_test]\n",
        "del(data) #remove to free memory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2luohEsdROk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "775a8b76-084c-4be0-99d6-8c6a9e80d511"
      },
      "source": [
        "print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set: 300000 Test set: 10240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNRMOYoGdnDi",
        "colab_type": "text"
      },
      "source": [
        "we only select question pair that are duplicate to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgfM9VUfdWB9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8f7ecead-b368-4a8d-8740-db4282f1b916"
      },
      "source": [
        "td_index = (data_train['is_duplicate'] == 1).to_numpy()\n",
        "td_index = [i for i, x in enumerate(td_index) if x]\n",
        "print('number of duiplicate questions: ', len(td_index))\n",
        "print('indexes of first ten duplicate questions:', td_index[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of duiplicate questions:  111473\n",
            "indexes of first ten duplicate questions: [5, 7, 11, 12, 13, 15, 16, 18, 20, 29]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDHdJjoyfMeW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "de6791d4-51ad-4e64-f2b7-7a50c24dd011"
      },
      "source": [
        "print(data_train['question1'][5])\n",
        "print(data_train['question2'][5])\n",
        "print('is_duplicate: ', data_train['is_duplicate'][5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
            "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
            "is_duplicate:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ZWXLtMgQTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q1_train_words = np.array(data_train['question1'][td_index])\n",
        "Q2_train_words = np.array(data_train['question2'][td_index])\n",
        "\n",
        "Q1_test_words = np.array(data_test['question1'])\n",
        "Q2_test_words = np.array(data_test['question2'])\n",
        "y_test  = np.array(data_test['is_duplicate'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jZP9AXVh9nQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "745da147-22f8-4dcd-ba6d-939b5f8c54a3"
      },
      "source": [
        "print('TRAINING QUESTIONS:\\n')\n",
        "print('Question 1: ', Q1_train_words[0])\n",
        "print('Question 2: ', Q2_train_words[0], '\\n')\n",
        "print('Question 1: ', Q1_train_words[5])\n",
        "print('Question 2: ', Q2_train_words[5], '\\n')\n",
        "\n",
        "print('TESTING QUESTIONS:\\n')\n",
        "print('Question 1: ', Q1_test_words[0])\n",
        "print('Question 2: ', Q2_test_words[0], '\\n')\n",
        "print('is_duplicate =', y_test[0], '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING QUESTIONS:\n",
            "\n",
            "Question 1:  Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
            "Question 2:  I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me? \n",
            "\n",
            "Question 1:  What would a Trump presidency mean for current international master’s students on an F1 visa?\n",
            "Question 2:  How will a Trump presidency affect the students presently in US or planning to study in US? \n",
            "\n",
            "TESTING QUESTIONS:\n",
            "\n",
            "Question 1:  What were some of the troubles you have faced during and after your 9 months period of pregnancy?\n",
            "Question 2:  What is the difference between neural circuit and neural system? \n",
            "\n",
            "is_duplicate = 0 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2At1DIfiC_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create arrays\n",
        "Q1_train = np.empty_like(Q1_train_words)\n",
        "Q2_train = np.empty_like(Q2_train_words)\n",
        "\n",
        "Q1_test = np.empty_like(Q1_test_words)\n",
        "Q2_test = np.empty_like(Q2_test_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6fD6MIbjnch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c7bd00c3-b7df-4c83-a277-0f8d352f55dd"
      },
      "source": [
        "# Building the vocabulary with the train set\n",
        "from collections import defaultdict\n",
        "\n",
        "vocab = defaultdict(lambda: 0)\n",
        "vocab['<PAD>'] = 1\n",
        "\n",
        "for idx in range(len(Q1_train_words)):\n",
        "  Q1_train[idx] = nltk.word_tokenize(Q1_train_words[idx])\n",
        "  Q2_train[idx] = nltk.word_tokenize(Q2_train_words[idx])\n",
        "  q = Q1_train[idx] + Q2_train[idx]\n",
        "  for word in q:\n",
        "    if word not in vocab:\n",
        "      vocab[word] = len(vocab) + 1\n",
        "print('The length of the vocabulary is:', len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the vocabulary is: 36352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j29ULZJim3Zl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "bdf9444b-2c07-4fb4-9783-2dd651b14e0a"
      },
      "source": [
        "print(vocab['<PAD>'])\n",
        "print(vocab['Astrology'])\n",
        "print(vocab['Astronomy'])  #not in vocabulary, returns 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNURJYAZnN2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx in range(len(Q1_test_words)):\n",
        "  Q1_test[idx] = nltk.word_tokenize(Q1_test_words[idx])\n",
        "  Q2_test[idx] = nltk.word_tokenize(Q2_test_words[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in6iYsvzp7VC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a06233d2-20d0-4b96-ce08-e45947376ba4"
      },
      "source": [
        "print('Train set has reduced to: ', len(Q1_train) ) \n",
        "print('Test set length: ', len(Q1_test) ) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set has reduced to:  111473\n",
            "Test set length:  10240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNfU4qFyrkK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting questions to array of integers\n",
        "for i in range(len(Q1_train)):\n",
        "    Q1_train[i] = [vocab[word] for word in Q1_train[i]]\n",
        "    Q2_train[i] = [vocab[word] for word in Q2_train[i]]\n",
        "          \n",
        "for i in range(len(Q1_test)):\n",
        "    Q1_test[i] = [vocab[word] for word in Q1_test[i]]\n",
        "    Q2_test[i] = [vocab[word] for word in Q2_test[i]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnsVGtkCs-vf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "df5756f0-df6e-41d3-9e9f-f68405703d90"
      },
      "source": [
        "print('first question in the train set:\\n')\n",
        "print(Q1_train_words[0], '\\n') \n",
        "print('encoded version:')\n",
        "print(Q1_train[0],'\\n')\n",
        "\n",
        "print('first question in the test set:\\n')\n",
        "print(Q1_test_words[0], '\\n')\n",
        "print('encoded version:')\n",
        "print(Q1_test[0]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first question in the train set:\n",
            "\n",
            "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \n",
            "\n",
            "encoded version:\n",
            "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] \n",
            "\n",
            "first question in the test set:\n",
            "\n",
            "What were some of the troubles you have faced during and after your 9 months period of pregnancy? \n",
            "\n",
            "encoded version:\n",
            "[30, 271, 116, 131, 78, 28882, 53, 218, 6595, 124, 11, 267, 56, 1636, 606, 2091, 131, 4329, 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlU4thq5t3ie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "e44fa136-edee-4466-b060-c60da4c8ca98"
      },
      "source": [
        "# Splitting the data\n",
        "cut_off = int(len(Q1_train)*.8)\n",
        "train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\n",
        "val_Q1, val_Q2 = Q1_train[cut_off: ], Q2_train[cut_off:]\n",
        "print('Number of duplicate questions: ', len(Q1_train))\n",
        "print(\"The length of the training set is:  \", len(train_Q1))\n",
        "print(\"The length of the validation set is: \", len(val_Q1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of duplicate questions:  111473\n",
            "The length of the training set is:   89178\n",
            "The length of the validation set is:  22295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siQK64Jk6gUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(Q1, Q2, batch_size, pad=1, shuffle=True):\n",
        "\n",
        "\n",
        "    input1 = []\n",
        "    input2 = []\n",
        "    idx = 0\n",
        "    len_q = len(Q1)\n",
        "    question_indexes = [*range(len_q)]\n",
        "    \n",
        "    if shuffle:\n",
        "        rnd.shuffle(question_indexes)\n",
        "    \n",
        "\n",
        "    while True:\n",
        "        if idx >= len_q:\n",
        "            idx = len_q\n",
        "            if shuffle:\n",
        "                rnd.shuffle(question_indexes)\n",
        "        \n",
        "        q1 = Q1[question_indexes[idx]]\n",
        "        q2 = Q2[question_indexes[idx]]\n",
        "        \n",
        "        idx += 1\n",
        "\n",
        "        input1.append(q1)\n",
        "        input2.append(q2)\n",
        "        if len(input1) == batch_size:\n",
        "            max_len = max(max([len(q) for q in input1]),\n",
        "                          max([len(q) for q in input2]))\n",
        "            max_len = 2**int(np.ceil(np.log2(max_len)))\n",
        "            b1 = []\n",
        "            b2 = []\n",
        "            for q1, q2 in zip(input1, input2):\n",
        "                q1 = q1 + [pad] * (max_len - len(q1))\n",
        "                q2 = q2 + [pad] * (max_len - len(q2))\n",
        "                b1.append(q1)\n",
        "                b2.append(q2)\n",
        "            yield np.array(b1), np.array(b2)\n",
        "            input1, input2 = [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4DaUTLzGXza",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "99cd1e44-720c-4e13-fb75-e6afd3efd78f"
      },
      "source": [
        "b = [1,2,4,23,235,3,25,235,25,324,46,54,2]\n",
        "a = len(b)\n",
        "c = [*range(a)]\n",
        "f = b[c[0]]\n",
        "print(c)\n",
        "print(a)\n",
        "print(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
            "13\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cat0OZPfyFN6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "6e9e70e2-502d-4dfb-8a68-0bb347bd79ff"
      },
      "source": [
        "batch_size = 64\n",
        "res1, res2 = next(data_generator(train_Q1, train_Q2, batch_size))\n",
        "print('First queation :', '\\n', res1, '\\n')\n",
        "print('seciond question :', '\\n',res2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First queation : \n",
            " [[  30   87  116 ...    1    1    1]\n",
            " [8843  572   39 ...    1    1    1]\n",
            " [ 283  111  156 ...    1    1    1]\n",
            " ...\n",
            " [ 168  905   62 ...    1    1    1]\n",
            " [ 356   78 7227 ...    1    1    1]\n",
            " [  32   38   53 ...    1    1    1]] \n",
            "\n",
            "seciond question : \n",
            " [[  30   87   78 ...    1    1    1]\n",
            " [  30   87   78 ...    1    1    1]\n",
            " [  30  156   78 ...    1    1    1]\n",
            " ...\n",
            " [  32   76  905 ...    1    1    1]\n",
            " [ 356   78 7227 ...    1    1    1]\n",
            " [  32   33    4 ...    1    1    1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gbd9vQJzVhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Siamese(vocab_size=len(vocab), d_model=128, mode='train'):\n",
        "  def normalize(x):\n",
        "    return x / fastnp.sqrt(fastnp.sum(x * x, axis=-1, keepdims = True))\n",
        "\n",
        "  q_processor = tl.Serial(\n",
        "      tl.Embedding(vocab_size, d_model),\n",
        "      tl.LSTM(d_model),\n",
        "      tl.Mean(axis=1),\n",
        "      tl.Fn('Normalize', lambda x : normalize(x)) \n",
        "  )\n",
        "\n",
        "  model = tl.Parallel(q_processor, q_processor)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iko5WSE2lB-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "6efc6b79-fcd6-40f6-f68e-bf051f8a3be5"
      },
      "source": [
        "# check your model\n",
        "model = Siamese()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parallel_in2_out2[\n",
            "  Serial[\n",
            "    Embedding_41794_128\n",
            "    LSTM_128\n",
            "    Mean\n",
            "    Normalize\n",
            "  ]\n",
            "  Serial[\n",
            "    Embedding_41794_128\n",
            "    LSTM_128\n",
            "    Mean\n",
            "    Normalize\n",
            "  ]\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQc3Mfu0l4t5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TripletLossFn(v1, v2, margin=0.25):\n",
        "  scores = fastnp.dot(v1, v2.T)\n",
        "  batch_size = len(scores)\n",
        "  positive = fastnp.diagonal(scores)\n",
        "  negative_without_positive = scores - 2.0 * fastnp.eye(batch_size)\n",
        "  closest_negative = negative_without_positive.max(axis=1)\n",
        "  negative_zero_on_duplicate = scores * (1.0 - fastnp.eye(batch_size))\n",
        "  mean_negative = np.sum(negative_zero_on_duplicate, axis=1) / (batch_size-1)\n",
        "  triplet_loss1 = fastnp.maximum(0.0, margin - positive + closest_negative)\n",
        "  triplet_loss2 = fastnp.maximum(0.0, margin - positive + mean_negative)\n",
        "  triplet_loss = fastnp.mean(triplet_loss1 + triplet_loss2)\n",
        "  return triplet_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2diTIISpmfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "de094b86-7b69-4fa4-98c8-fbc62dbc7507"
      },
      "source": [
        "v1 = np.array([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\n",
        "v2 = np.array([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])\n",
        "TripletLossFn(v2,v1)\n",
        "print(\"Triplet Loss:\", TripletLossFn(v2,v1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Triplet Loss: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6zt_xCBqNza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import partial\n",
        "def TripletLoss(margin=0.25):\n",
        "    triplet_loss_fn = partial(TripletLossFn, margin=margin)\n",
        "    return tl.Fn('TripletLoss', triplet_loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_NefqWvqQN0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "80676c25-dc0d-4528-a7f8-01318ced1d5d"
      },
      "source": [
        "batch_size = 128\n",
        "train_generator = data_generator(train_Q1, train_Q2, batch_size, vocab['<PAD>'])\n",
        "val_generator = data_generator(val_Q1, val_Q2, batch_size, vocab['<PAD>'])\n",
        "print('train_Q1.shape ', train_Q1.shape)\n",
        "print('val_Q1.shape   ', val_Q1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_Q1.shape  (89178,)\n",
            "val_Q1.shape    (22295,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scSJS0Htqvv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_schedule = trax.lr.warmup_and_rsqrt_decay(400, 0.01)\n",
        "def train_model(Siamese, TripletLoss,lr_schedule, train_generator=train_generator, \n",
        "                val_generator=val_generator, output_dir='model/'):\n",
        "\n",
        "  output_dir = os.path.expanduser(output_dir)\n",
        "\n",
        "  train_task = training.TrainTask(\n",
        "        labeled_data = train_generator,         # Use generator (train)\n",
        "        loss_layer = TripletLoss(),             # Use triplet loss. Don't forget to instantiate this object\n",
        "        optimizer = trax.optimizers.Adam(0.01), # Don't forget to add the learning rate parameter\n",
        "        lr_schedule=lr_schedule,              # Use Trax multifactor schedule function\n",
        "        n_steps_per_checkpoint = 10\n",
        "    )\n",
        "\n",
        "  eval_task = training.EvalTask(\n",
        "        labeled_data = val_generator,       # Use generator (val)\n",
        "        metrics = [TripletLoss()])          # Use triplet loss. Don't forget to instantiate this object\n",
        "\n",
        "  training_loop = training.Loop(Siamese(),\n",
        "                                  train_task,\n",
        "                                  eval_tasks = [eval_task],\n",
        "                                  output_dir = output_dir)\n",
        "\n",
        "  return training_loop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8NJrUWPr1I4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dba0cc32-747a-4ada-b3ad-47bcadcc267a"
      },
      "source": [
        "train_steps = 500\n",
        "training_loop = train_model(Siamese, TripletLoss, lr_schedule)\n",
        "training_loop.run(train_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Step      1: Ran 1 train steps in 3.16 secs\n",
            "Step      1: train TripletLoss |  0.49693477\n",
            "Step      1: eval  TripletLoss |  0.49887902\n",
            "\n",
            "Step     10: Ran 9 train steps in 4.47 secs\n",
            "Step     10: train TripletLoss |  0.49902451\n",
            "Step     10: eval  TripletLoss |  0.49959910\n",
            "\n",
            "Step     20: Ran 10 train steps in 1.73 secs\n",
            "Step     20: train TripletLoss |  0.49791786\n",
            "Step     20: eval  TripletLoss |  0.49721932\n",
            "\n",
            "Step     30: Ran 10 train steps in 1.75 secs\n",
            "Step     30: train TripletLoss |  0.48867178\n",
            "Step     30: eval  TripletLoss |  0.49656379\n",
            "\n",
            "Step     40: Ran 10 train steps in 3.69 secs\n",
            "Step     40: train TripletLoss |  0.48058835\n",
            "Step     40: eval  TripletLoss |  0.42655259\n",
            "\n",
            "Step     50: Ran 10 train steps in 1.85 secs\n",
            "Step     50: train TripletLoss |  0.43212983\n",
            "Step     50: eval  TripletLoss |  0.39185748\n",
            "\n",
            "Step     60: Ran 10 train steps in 1.88 secs\n",
            "Step     60: train TripletLoss |  0.39067763\n",
            "Step     60: eval  TripletLoss |  0.40240365\n",
            "\n",
            "Step     70: Ran 10 train steps in 1.87 secs\n",
            "Step     70: train TripletLoss |  0.36079255\n",
            "Step     70: eval  TripletLoss |  0.32528800\n",
            "\n",
            "Step     80: Ran 10 train steps in 1.90 secs\n",
            "Step     80: train TripletLoss |  0.33736750\n",
            "Step     80: eval  TripletLoss |  0.28216755\n",
            "\n",
            "Step     90: Ran 10 train steps in 1.99 secs\n",
            "Step     90: train TripletLoss |  0.28868181\n",
            "Step     90: eval  TripletLoss |  0.22910577\n",
            "\n",
            "Step    100: Ran 10 train steps in 1.99 secs\n",
            "Step    100: train TripletLoss |  0.25940102\n",
            "Step    100: eval  TripletLoss |  0.25397858\n",
            "\n",
            "Step    110: Ran 10 train steps in 2.01 secs\n",
            "Step    110: train TripletLoss |  0.22527468\n",
            "Step    110: eval  TripletLoss |  0.21732624\n",
            "\n",
            "Step    120: Ran 10 train steps in 2.10 secs\n",
            "Step    120: train TripletLoss |  0.22062388\n",
            "Step    120: eval  TripletLoss |  0.18544075\n",
            "\n",
            "Step    130: Ran 10 train steps in 2.04 secs\n",
            "Step    130: train TripletLoss |  0.20545654\n",
            "Step    130: eval  TripletLoss |  0.18344609\n",
            "\n",
            "Step    140: Ran 10 train steps in 2.12 secs\n",
            "Step    140: train TripletLoss |  0.18520460\n",
            "Step    140: eval  TripletLoss |  0.17918698\n",
            "\n",
            "Step    150: Ran 10 train steps in 2.11 secs\n",
            "Step    150: train TripletLoss |  0.18393230\n",
            "Step    150: eval  TripletLoss |  0.15921092\n",
            "\n",
            "Step    160: Ran 10 train steps in 2.12 secs\n",
            "Step    160: train TripletLoss |  0.16238675\n",
            "Step    160: eval  TripletLoss |  0.17126569\n",
            "\n",
            "Step    170: Ran 10 train steps in 2.26 secs\n",
            "Step    170: train TripletLoss |  0.16735156\n",
            "Step    170: eval  TripletLoss |  0.14261195\n",
            "\n",
            "Step    180: Ran 10 train steps in 2.19 secs\n",
            "Step    180: train TripletLoss |  0.15547912\n",
            "Step    180: eval  TripletLoss |  0.12525791\n",
            "\n",
            "Step    190: Ran 10 train steps in 2.28 secs\n",
            "Step    190: train TripletLoss |  0.15417956\n",
            "Step    190: eval  TripletLoss |  0.12016776\n",
            "\n",
            "Step    200: Ran 10 train steps in 2.24 secs\n",
            "Step    200: train TripletLoss |  0.14290527\n",
            "Step    200: eval  TripletLoss |  0.12463740\n",
            "\n",
            "Step    210: Ran 10 train steps in 2.27 secs\n",
            "Step    210: train TripletLoss |  0.15571061\n",
            "Step    210: eval  TripletLoss |  0.15087382\n",
            "\n",
            "Step    220: Ran 10 train steps in 2.27 secs\n",
            "Step    220: train TripletLoss |  0.13801858\n",
            "Step    220: eval  TripletLoss |  0.14707890\n",
            "\n",
            "Step    230: Ran 10 train steps in 2.31 secs\n",
            "Step    230: train TripletLoss |  0.13369437\n",
            "Step    230: eval  TripletLoss |  0.12177362\n",
            "\n",
            "Step    240: Ran 10 train steps in 2.31 secs\n",
            "Step    240: train TripletLoss |  0.13324369\n",
            "Step    240: eval  TripletLoss |  0.13284710\n",
            "\n",
            "Step    250: Ran 10 train steps in 2.34 secs\n",
            "Step    250: train TripletLoss |  0.12348006\n",
            "Step    250: eval  TripletLoss |  0.11505554\n",
            "\n",
            "Step    260: Ran 10 train steps in 2.42 secs\n",
            "Step    260: train TripletLoss |  0.12475161\n",
            "Step    260: eval  TripletLoss |  0.14337546\n",
            "\n",
            "Step    270: Ran 10 train steps in 2.36 secs\n",
            "Step    270: train TripletLoss |  0.11125878\n",
            "Step    270: eval  TripletLoss |  0.11807679\n",
            "\n",
            "Step    280: Ran 10 train steps in 2.41 secs\n",
            "Step    280: train TripletLoss |  0.11572061\n",
            "Step    280: eval  TripletLoss |  0.10540375\n",
            "\n",
            "Step    290: Ran 10 train steps in 2.43 secs\n",
            "Step    290: train TripletLoss |  0.10979964\n",
            "Step    290: eval  TripletLoss |  0.09657312\n",
            "\n",
            "Step    300: Ran 10 train steps in 2.44 secs\n",
            "Step    300: train TripletLoss |  0.10691670\n",
            "Step    300: eval  TripletLoss |  0.09688173\n",
            "\n",
            "Step    310: Ran 10 train steps in 2.54 secs\n",
            "Step    310: train TripletLoss |  0.10142752\n",
            "Step    310: eval  TripletLoss |  0.09535708\n",
            "\n",
            "Step    320: Ran 10 train steps in 2.53 secs\n",
            "Step    320: train TripletLoss |  0.10173390\n",
            "Step    320: eval  TripletLoss |  0.10602394\n",
            "\n",
            "Step    330: Ran 10 train steps in 2.58 secs\n",
            "Step    330: train TripletLoss |  0.10167805\n",
            "Step    330: eval  TripletLoss |  0.11505525\n",
            "\n",
            "Step    340: Ran 10 train steps in 2.58 secs\n",
            "Step    340: train TripletLoss |  0.10311258\n",
            "Step    340: eval  TripletLoss |  0.10188244\n",
            "\n",
            "Step    350: Ran 10 train steps in 2.53 secs\n",
            "Step    350: train TripletLoss |  0.08654832\n",
            "Step    350: eval  TripletLoss |  0.12253170\n",
            "\n",
            "Step    360: Ran 10 train steps in 2.50 secs\n",
            "Step    360: train TripletLoss |  0.10000515\n",
            "Step    360: eval  TripletLoss |  0.10540707\n",
            "\n",
            "Step    370: Ran 10 train steps in 2.90 secs\n",
            "Step    370: train TripletLoss |  0.09469870\n",
            "Step    370: eval  TripletLoss |  0.08756450\n",
            "\n",
            "Step    380: Ran 10 train steps in 2.60 secs\n",
            "Step    380: train TripletLoss |  0.09627909\n",
            "Step    380: eval  TripletLoss |  0.10313118\n",
            "\n",
            "Step    390: Ran 10 train steps in 2.61 secs\n",
            "Step    390: train TripletLoss |  0.09465795\n",
            "Step    390: eval  TripletLoss |  0.12024384\n",
            "\n",
            "Step    400: Ran 10 train steps in 2.62 secs\n",
            "Step    400: train TripletLoss |  0.09250459\n",
            "Step    400: eval  TripletLoss |  0.11223476\n",
            "\n",
            "Step    410: Ran 10 train steps in 2.70 secs\n",
            "Step    410: train TripletLoss |  0.09811193\n",
            "Step    410: eval  TripletLoss |  0.09848866\n",
            "\n",
            "Step    420: Ran 10 train steps in 2.66 secs\n",
            "Step    420: train TripletLoss |  0.08927371\n",
            "Step    420: eval  TripletLoss |  0.07200456\n",
            "\n",
            "Step    430: Ran 10 train steps in 2.66 secs\n",
            "Step    430: train TripletLoss |  0.08861967\n",
            "Step    430: eval  TripletLoss |  0.07798767\n",
            "\n",
            "Step    440: Ran 10 train steps in 2.73 secs\n",
            "Step    440: train TripletLoss |  0.09032585\n",
            "Step    440: eval  TripletLoss |  0.08987622\n",
            "\n",
            "Step    450: Ran 10 train steps in 2.64 secs\n",
            "Step    450: train TripletLoss |  0.07793608\n",
            "Step    450: eval  TripletLoss |  0.07651357\n",
            "\n",
            "Step    460: Ran 10 train steps in 2.69 secs\n",
            "Step    460: train TripletLoss |  0.08988651\n",
            "Step    460: eval  TripletLoss |  0.11070195\n",
            "\n",
            "Step    470: Ran 10 train steps in 2.73 secs\n",
            "Step    470: train TripletLoss |  0.08572519\n",
            "Step    470: eval  TripletLoss |  0.09955698\n",
            "\n",
            "Step    480: Ran 10 train steps in 2.59 secs\n",
            "Step    480: train TripletLoss |  0.07714980\n",
            "Step    480: eval  TripletLoss |  0.06523981\n",
            "\n",
            "Step    490: Ran 10 train steps in 2.51 secs\n",
            "Step    490: train TripletLoss |  0.07817405\n",
            "Step    490: eval  TripletLoss |  0.08135302\n",
            "\n",
            "Step    500: Ran 10 train steps in 2.57 secs\n",
            "Step    500: train TripletLoss |  0.07705017\n",
            "Step    500: eval  TripletLoss |  0.07964014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd5-IYUl7Hd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading in the saved model\n",
        "model = Siamese()\n",
        "model.init_from_file('/content/model/model.pkl.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QYp9U8p8g6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(test_Q1, test_Q2, y, threshold, model, vocab, data_generator=data_generator, batch_size=64):\n",
        "  accuracy = 0\n",
        "  for i in range(0, len(test_Q1), batch_size):\n",
        "    q1, q2 = next(data_generator(test_Q1[i:i + batch_size], test_Q2[i:i + batch_size], batch_size, vocab['<PAD>'], shuffle=False))\n",
        "    y_test = y[i:i + batch_size]\n",
        "    v1, v2 =model((q1, q2))\n",
        "    for j in range(batch_size):\n",
        "      d = np.dot(v1[j], v2[j].T)\n",
        "      res = d > threshold\n",
        "      accuracy += (y_test[j] == res)\n",
        "  accuracy = accuracy / len(test_Q1)\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTcchE699OrC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3018d396-a4ea-4659-c09b-5db185f842f3"
      },
      "source": [
        "accuracy = classify(Q1_test, Q2_test, y_test, 0.7, model, vocab, batch_size = 512) \n",
        "print(\"Accuracy\", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.70654296875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukG59wOaSQrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(question1, question2, threshold, model, vocab, data_generator=data_generator, verbose=False):\n",
        "  q1 = nltk.word_tokenize(question1) \n",
        "  q2 = nltk.word_tokenize(question2)\n",
        "\n",
        "  Q1, Q2 = [], []\n",
        "  for word in q1:\n",
        "    Q1 += [vocab[word]]\n",
        "  for word in q2:\n",
        "    Q2 += [vocab[word]]\n",
        "\n",
        "  Q1, Q2 = next(data_generator([Q1], [Q2], 1, vocab['<PAD>']))\n",
        "  v1, v2 = model((Q1, Q2))\n",
        "  d = np.dot(v1[0], v2[0].T)\n",
        "  res = d > threshold\n",
        "\n",
        "  if(verbose):\n",
        "    print(\"Q1  = \", Q1, \"\\nQ2  = \", Q2)\n",
        "    print(\"d   = \", d)\n",
        "    print(\"res = \", res)\n",
        "\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxdU71OCSwwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "1db853f5-d7e6-4262-cb14-a8e7bc620770"
      },
      "source": [
        "question1 = \"When will I see you?\"\n",
        "question2 = \"When can I see you again?\"\n",
        "# 1 means it is duplicated, 0 otherwise\n",
        "predict(question1 , question2, 0.7, model, vocab, verbose = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q1  =  [[585  76   4  46  53  21   1   1]] \n",
            "Q2  =  [[ 585   33    4   46   53 7287   21    1]]\n",
            "d   =  0.8535244\n",
            "res =  True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jkHWzIdT5HL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "221b450e-75c9-4cc4-a348-249b65215b27"
      },
      "source": [
        "question1 = \"I had mad fun at club\"\n",
        "question2 = \"had mad fun at club\"\n",
        "# 1 means it is duplicated, 0 otherwise\n",
        "predict(question1 , question2, 0.7, model, vocab, verbose = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q1  =  [[    4   813 18210  4566   129 10501     1     1]] \n",
            "Q2  =  [[  813 18210  4566   129 10501     1     1     1]]\n",
            "d   =  0.8329049\n",
            "res =  True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    }
  ]
}